{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "from yacs.config import CfgNode as CN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../0.mc_utils/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpose.op_formats import NPMapOP25bToSMPL24\n",
    "from openpose.op_utils import draw_kp2d_to_image,draw_reided_bboxes\n",
    "from common.mincostflow import MinCostFlowReID\n",
    "\n",
    "from mqtt_player.unity3d_mqtt_player import Unity3DMqttPlayer,MQTTPLAYER_CFG\n",
    "\n",
    "from mchmr2.hmr_cfg import HMR_ENCODER\n",
    "from mchmr2.hmr_encoder import HMREncoder\n",
    "\n",
    "from pipeline.global_cfg import CFG_MVIEW\n",
    "from pipeline.mview_x2ds_to_A import SingleX2dsReID,SimpleHMREncoder,HMRWrapper\n",
    "from pipeline.pipeline_utils import ComputeSMPL24CameraTrajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##main view\n",
    "op25b_x2ds0 = np.load(\"E:/4.test_videos/yunpeng_mview/01/video_0.npz\",allow_pickle=True)[\"op25b\"].item()\n",
    "video0_fname = \"E:/4.test_videos/yunpeng_mview/01/video_0.mp4\"\n",
    "\n",
    "##sub view\n",
    "op25b_x2ds1 = np.load(\"E:/4.test_videos/yunpeng_mview/01/video_1.npz\",allow_pickle=True)[\"op25b\"].item()\n",
    "video1_fname = \"E:/4.test_videos/yunpeng_mview/01/video_1.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MViewX2dsToA:\n",
    "    def __init__(self,cfg=CFG_MVIEW):\n",
    "        self.cfg = cfg.clone()\n",
    "        self.main_camera = cfg.main_camera\n",
    "        self.sub_camera = cfg.sub_camera\n",
    "        #single hmr\n",
    "        self.hmr_single = HMRWrapper(cfg)\n",
    "        #fusion hmr\n",
    "        self.hmr_fusioner = SimpleHMREncoder(cfg.fusion)\n",
    "        \n",
    "        #traj solver\n",
    "        self.traj_solver = ComputeSMPL24CameraTrajectory(cfg.K,cfg.traj_offset)\n",
    "        \n",
    "        #cross and temporal matching\n",
    "        self.cross_km = MinCostFlowReID()\n",
    "        self.single_x2ds_reid = {}\n",
    "        for i in cfg.cameras:\n",
    "            self.single_x2ds_reid[i] = SingleX2dsReID(cfg)\n",
    "\n",
    "    def crossview_pairing(self,f0,f1):\n",
    "        \"\"\"\n",
    "        maping f0 to f1\n",
    "        fx is NxD\n",
    "        fx are tensor object\n",
    "        \"\"\"\n",
    "        M = f0.shape[0]\n",
    "        N = f1.shape[0]\n",
    "        \n",
    "        ##step1. extand features\n",
    "        new_f0 = f0.unsqueeze(1).repeat(1,N,1)#MxNxD\n",
    "        new_f1 = f1.unsqueeze(0).repeat(M,1,1)#MxNxD\n",
    "        \n",
    "        ##step3.KM assign\n",
    "        cost_mat = torch.norm(new_f0-new_f1,dim=-1)\n",
    "        assign = self.cross_km(cost_mat.cpu().numpy().astype(np.int))\n",
    "        return assign\n",
    "    \n",
    "    def push(self,index,x2ds_dict):\n",
    "        \"\"\"\n",
    "        x2ds_dict: key is camera name, value is Mx24x2\n",
    "        return:\n",
    "        @matched: \n",
    "            hids,M\n",
    "            x2ds,MxCx24x2\n",
    "            norm_x2ds,MxCx24x2\n",
    "        @unmached:\n",
    "            hids,N\n",
    "            x2ds,Nx24x2\n",
    "            hmr_return,Nx48\n",
    "        \"\"\"\n",
    "        assert isinstance(x2ds_dict,dict)\n",
    "        \n",
    "        #step1.singleview forward\n",
    "        N = x2ds_dict[self.main_camera].shape[0]\n",
    "        main_hids = None\n",
    "        reid_x2ds_dict = {}\n",
    "        reid_humans_dict = {}\n",
    "        reid_slice_dict = {}\n",
    "        counter = 0\n",
    "        for k in x2ds_dict:\n",
    "            ret = self.single_x2ds_reid[k].push(index,x2ds_dict[k])##x2ds and hids\n",
    "            if k==self.main_camera:\n",
    "                main_hids = ret[\"hids\"]\n",
    "            reid_x2ds_dict[k]=ret[\"x2ds\"]#tensor of Nx24x2\n",
    "            reid_humans_dict[k] = ret[\"humans\"]\n",
    "            reid_slice_dict[k] = slice(counter,counter+ret[\"x2ds\"].shape[0])\n",
    "            counter += ret[\"x2ds\"].shape[0]\n",
    "        \n",
    "        ##step2.hmr simple forward\n",
    "        hmr_ret = self.hmr_single(torch.cat(list(reid_x2ds_dict.values())))\n",
    "        norm_x2ds0 = hmr_ret[\"x\"][reid_slice_dict[self.main_camera]]\n",
    "        norm_x2ds1 = hmr_ret[\"x\"][reid_slice_dict[self.sub_camera]]\n",
    "        f0 = hmr_ret[\"y\"][reid_slice_dict[self.main_camera]]\n",
    "        f1 = hmr_ret[\"y\"][reid_slice_dict[self.sub_camera]]\n",
    "        \n",
    "        #step2.cross matching\n",
    "        cross_assign = self.crossview_pairing(f0[:,6:38],f1[:,6:38])\n",
    "        \n",
    "        \n",
    "        #step3.match x2ds\n",
    "        matched_dict = {\"hids\":[],\n",
    "                        \"x2ds\":[],\n",
    "                        \"norm_x2ds\":[]}\n",
    "        unmatched_dict = {\"hids\":[],\n",
    "                          \"x2ds\":[],\n",
    "                          \"hmrs\":[]}\n",
    "        for i in range(N):\n",
    "            x0 = reid_x2ds_dict[self.main_camera][i]\n",
    "            hid = main_hids[i]\n",
    "            if i in cross_assign:\n",
    "                mid = cross_assign[i][0] # matched index in subview\n",
    "                x1 = reid_x2ds_dict[self.sub_camera][mid]#24x2\n",
    "                matched_dict[\"hids\"].append(hid)\n",
    "                matched_dict[\"x2ds\"].append(torch.stack([x0,x1]))\n",
    "                matched_dict[\"norm_x2ds\"].append(torch.stack([norm_x2ds0[i],norm_x2ds1[mid]]))\n",
    "            else:\n",
    "                unmatched_dict[\"hids\"].append(hid)\n",
    "                unmatched_dict[\"x2ds\"].append(x0)\n",
    "                unmatched_dict[\"hmrs\"].append(f0[i])\n",
    "        final_hids = matched_dict[\"hids\"] + unmatched_dict[\"hids\"]\n",
    "        \n",
    "        ##matched\n",
    "        if len(matched_dict[\"hids\"])>0:\n",
    "            matched_dict[\"x2ds\"] = torch.stack(matched_dict[\"x2ds\"])\n",
    "            matched_dict[\"norm_x2ds\"] = torch.stack(matched_dict[\"norm_x2ds\"])\n",
    "        else:\n",
    "            matched_dict = None\n",
    "        ##unmatched\n",
    "        if len(unmatched_dict[\"hids\"])>0:\n",
    "            unmatched_dict[\"x2ds\"] = torch.stack(unmatched_dict[\"x2ds\"])\n",
    "            unmatched_dict[\"hmrs\"] = torch.stack(unmatched_dict[\"hmrs\"])\n",
    "        else:\n",
    "            unmatched_dict = None\n",
    "        \n",
    "        ##step4.matched x2ds to A\n",
    "        final_A = []\n",
    "        if matched_dict is not None:\n",
    "            ret = self.hmr_fusioner.forward_hmr(matched_dict[\"norm_x2ds\"])\n",
    "            matched_A = self.hmr_fusioner.forward_smpl(ret[\"root_r6d\"],ret[\"pose_r6d\"])\n",
    "            final_A.append(matched_A)\n",
    "            \n",
    "        if unmatched_dict is not None:\n",
    "            ##step5.unmatched x2ds to A\n",
    "            with torch.no_grad():\n",
    "                root_r6d = unmatched_dict[\"hmrs\"][:,:6]\n",
    "                pose_r6d = self.hmr_fusioner.vposer.decode(unmatched_dict[\"hmrs\"][:,6:38])[\"r6d\"]\n",
    "            unmatched_A = self.hmr_fusioner.forward_smpl(root_r6d,pose_r6d)\n",
    "            final_A.append(unmatched_A)\n",
    "        final_A = torch.cat(final_A)\n",
    "        final_A = final_A.cpu().numpy()\n",
    "        \n",
    "        ##step5.compute traj\n",
    "        trajs = self.traj_solver(reid_x2ds_dict[self.main_camera].numpy(),final_A[...,:3,-1])#Nx3\n",
    "        for i in range(N):\n",
    "            trajs[i,[0,2]] = reid_humans_dict[self.main_camera][i].traj_filter(index,trajs[i,[0,2]])\n",
    "            final_A[i,:,:3,-1] += trajs[i].reshape(1,3)  #update traj in A \n",
    "        final_A = np.matmul(self.traj_solver.camera_to_world_R,final_A)\n",
    "        return {\"A\":final_A,\n",
    "                \"hids\":final_hids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>Loaded HMR from:../12.models/mchmr2/20200516-hmrzero-b4f2048s10-vposer0420.pth\n",
      ">>>Loaded HMR from:../12.models/mchmr2/20200528-hmrzeofusion-x2b5f2048s5-vposer0420.pth\n",
      ">>>Loaded VPoser from:../12.models/mchmr2/20200420-vposer1024-lt32b3.pth\n"
     ]
    }
   ],
   "source": [
    "map_op25b_to_smpl24 = NPMapOP25bToSMPL24()\n",
    "mview_x2ds_to_A = MViewX2dsToA(CFG_MVIEW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_name = \"reID window\"\n",
    "cv2.namedWindow(window_name)\n",
    "## video1\n",
    "cap0 = cv2.VideoCapture(video0_fname)\n",
    "h0 = int(cap0.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "w0 = int(cap0.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "## video2\n",
    "cap1 = cv2.VideoCapture(video1_fname)\n",
    "h1 = int(cap1.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "w1 = int(cap1.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "\n",
    "height = h0+h1\n",
    "width = max(w0 , w1)\n",
    "canvas = np.zeros((height, width, 3),dtype=np.uint8)\n",
    "mqtt_player = Unity3DMqttPlayer(MQTTPLAYER_CFG)\n",
    "\n",
    "for i in range(1000):\n",
    "    is_valid0,frame0 = cap0.read()\n",
    "    is_valid1,frame1 = cap1.read()\n",
    "    if not is_valid0 or not is_valid1:\n",
    "        break\n",
    "        \n",
    "    #step1.load data from each view\n",
    "    if i in op25b_x2ds0 and i in op25b_x2ds1:\n",
    "        ts = time.time()\n",
    "        ##step1.load x2ds\n",
    "        x2ds0 = map_op25b_to_smpl24(op25b_x2ds0[i])[...,:2] #Nx24x3\n",
    "        x2ds1 = map_op25b_to_smpl24(op25b_x2ds1[i])[...,:2] #Mx24x3\n",
    "        \n",
    "        ret = mview_x2ds_to_A.push(i,{0:x2ds0,1:x2ds1})\n",
    "        mqtt_player(ret[\"hids\"],ret[\"A\"].reshape(-1,384))\n",
    "        ts = time.time()-ts\n",
    "    \n",
    "    canvas[:h0] = frame0\n",
    "    canvas[h0:] = frame1\n",
    "    new_canvas = cv2.resize(canvas,(800,900))\n",
    "    cv2.imshow(window_name,new_canvas)\n",
    "    if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
