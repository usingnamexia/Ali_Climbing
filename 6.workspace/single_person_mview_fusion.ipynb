{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../0.mc_utils/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cameras.single3d_mats import qslerp,rot6d_to_rotmat,rodrigues2quat,quat2rodrigues\n",
    "from openpose.op_formats import NPMapOP25bToSMPL24\n",
    "from openpose.op_utils import draw_kp2d_to_image,draw_reided_bboxes\n",
    "from mqtt_player.unity3d_mqtt_player import Unity3DMqttPlayer,MQTTPLAYER_CFG\n",
    "from common.unity_visualizer import export_Amatrix,play_kp2ds_animation\n",
    "from common.torch_x2ds_normalizer import XBBoxNormalier\n",
    "from mchmr2.hmr_cfg import HMR_ENCODER\n",
    "from mchmr2.hmr_encoder import HMREncoder\n",
    "from common.tools_cv import draw_kp\n",
    "\n",
    "from pipeline.pipeline_utils import ComputeSMPL24CameraTrajectory\n",
    "from pipeline.human_instance import SMPL24HumanInstance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "op25b_x2ds0 = np.load(\"C:/Users/mc/Desktop/surfing/pose1/2dpose.npz\",allow_pickle=True)[\"op25b\"].item()\n",
    "video0_fname = \"C:/Users/mc/Desktop/surfing/write_C0001_create.mp4\"\n",
    "\n",
    "##sub view\n",
    "op25b_x2ds1 = np.load(\"C:/Users/mc/Desktop/surfing/pose2/2dpose.npz\",allow_pickle=True)[\"op25b\"].item()\n",
    "video1_fname = \"C:/Users/mc/Desktop/surfing/write_C0002_create.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mview_cfg = HMR_ENCODER.clone()\n",
    "mview_cfg.hmr.model = \"../12.models/mchmr2/20200510-hmrzeofusion-x2b5f2048s5-vposer0420-30.25.pth\"\n",
    "mview_cfg.hmr.in_features=96\n",
    "mview_cfg.hmr.out_features=6+32+5\n",
    "mview_cfg.hmr.blocks=5\n",
    "mview_cfg.freeze()\n",
    "# print(mview_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>Loaded HMR from:../12.models/mchmr2/20200510-hmrzeofusion-x2b5f2048s5-vposer0420-30.25.pth\n",
      ">>>Loaded VPoser from:../12.models/mchmr2/20200420-vposer1024-lt32b3.pth\n"
     ]
    }
   ],
   "source": [
    "map_op25b_to_smpl24 = NPMapOP25bToSMPL24()\n",
    "compute_traj = ComputeSMPL24CameraTrajectory(K=[1145,1145,1920/2,1080/2],traj_offset=[0.0,-1.2,0.0])\n",
    "human0 = SMPL24HumanInstance()\n",
    "human1 = SMPL24HumanInstance()\n",
    "hmr_fusioner = HMREncoder(mview_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# triangulated_traj = np.load(f'{os.path.dirname(video0_fname)}/trajs.npy').reshape((-1,1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1482"
     ]
    }
   ],
   "source": [
    "mview_x2ds_dict = {}\n",
    "A_list = []\n",
    "r6d_list = []\n",
    "traj_list = []\n",
    "human0.reset()\n",
    "human1.reset()\n",
    "iss = []\n",
    "for i in range(10000):\n",
    "    if i in op25b_x2ds0 and i in op25b_x2ds1:\n",
    "        ##step1.load x2ds\n",
    "        print('\\r%i'%(i),end='')\n",
    "        x2ds0 = map_op25b_to_smpl24(op25b_x2ds0[i])[...,:2] #1x24x3\n",
    "        x2ds1 = map_op25b_to_smpl24(op25b_x2ds1[i])[...,:2] #1x24x3\n",
    "        mview_x2ds_dict[i] = [x2ds0[:1],x2ds1[:1]]\n",
    "        \n",
    "        ##step2.smoother\n",
    "        x2ds0 = human0.update_x2ds(i,torch.from_numpy(x2ds0).to(torch.float32)[0]).unsqueeze(0)\n",
    "        x2ds1 = human1.update_x2ds(i,torch.from_numpy(x2ds1).to(torch.float32)[0]).unsqueeze(0)\n",
    "        \n",
    "        ##step3.fusioner\n",
    "        x = torch.stack([x2ds0,x2ds1],dim=1)\n",
    "        ret = hmr_fusioner.forward_hmr(x)\n",
    "        ret[\"root_r6d\"][0] = human0.root_filter(i,ret[\"root_r6d\"][0])\n",
    "        ret[\"pose_r6d\"][0] = human0.pose_filter(i,ret[\"pose_r6d\"][0])\n",
    "        r6d_list.append(torch.cat([ret[\"root_r6d\"][0].unsqueeze(0),ret[\"pose_r6d\"][0]],dim=0))\n",
    "        \n",
    "        A = hmr_fusioner.forward_smpl(ret[\"root_r6d\"],ret[\"pose_r6d\"]).cpu().numpy()\n",
    "        \n",
    "#         trajs = triangulated_traj[i:i+1]*np.array([[-1,1,1]])+np.array([[0.0,-1.2,0.0]])\n",
    "#         trajs[0,[0,2]] = human0.traj_filter(i,trajs[0,[0,2]])\n",
    "#         traj_list.append(trajs[0])\n",
    "        \n",
    "#         A[0,:,:3,-1] += trajs[0].reshape(1,3)  #update traj in A\n",
    "        A = np.matmul(compute_traj.camera_to_world_R,A)\n",
    "        A_list.append(A)\n",
    "np_A = np.array(A_list)\n",
    "path= 'C:/Users/mc/Desktop/surfing'\n",
    "np.save(path+'/3dpose.npy',np_A)\n",
    "np_A = np_A.reshape((-1,384))\n",
    "fps = np.ones((1,384))*30\n",
    "np_A = np.concatenate([fps,np_A])\n",
    "np.savetxt(path+'/3dpose.txt',np_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Amats = A.copy()\n",
    "Amats = Amats.squeeze()\n",
    "\n",
    "# trajs = np.load(f'{os.path.dirname(video0_fname)}/trajs.npy').reshape((-1,1,3))\n",
    "# trajs[:,:,1] += 1.05\n",
    "# N = min(Amats.shape[0],trajs.shape[0])\n",
    "# print(Amats[:N,:,0:3,3].shape, trajs[:N].shape)\n",
    "# Amats[:N,:,0:3,3]+=trajs[:N]\n",
    "\n",
    "Amats = Amats.squeeze().reshape((-1,384))\n",
    "export_Amatrix(f'{video0_fname[:-4]}_new_fusion.txt', Amats, fps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1801, 384)\n"
     ]
    }
   ],
   "source": [
    "rs = np.load(f'{os.path.dirname(video0_fname)}/rs.npy')\n",
    "rs = torch.tensor(rs).type(torch.float32)\n",
    "body_quats = body_quats_.cpu()\n",
    "R = quat2rodrigues(body_quats.reshape(-1,4)).reshape(-1,24,3,3)\n",
    "\n",
    "N = min(R.shape[0],rs.shape[0])\n",
    "R[:N,[20,21]] = rs[:N]\n",
    "\n",
    "R = R.cuda()\n",
    "Amats = hmr_fusioner.smpl(root_rot=R[:,0],pose_rot=R[:,1:]).cpu().numpy()\n",
    "\n",
    "# trajs = np.load(f'{os.path.dirname(video0_fname)}/trajs.npy').reshape((-1,1,3))\n",
    "# trajs[:,:,1] += -1.1\n",
    "# N = min(A.shape[0],trajs.shape[0])\n",
    "# A[:N,:,0:3,3]+=trajs[:N]\n",
    "\n",
    "Amats = np.matmul(compute_traj.camera_to_world_R, Amats)\n",
    "Amats = Amats.squeeze().reshape((-1,384)).astype(np.float32)\n",
    "print(Amats.shape)\n",
    "export_Amatrix(f'{video0_fname[:-4]}_add_hand.txt', Amats, fps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0---> torch.Size([1801, 24, 4])\n",
      "1---> torch.Size([181, 24, 4])\n",
      "2---> torch.Size([1801, 24, 4])\n"
     ]
    }
   ],
   "source": [
    "##step2.interpolate quats\n",
    "l = 10\n",
    "\n",
    "print('0--->', body_quats_.shape)\n",
    "body_quats = body_quats_.cpu()[::l]\n",
    "print('1--->',body_quats.shape)\n",
    "new_quats_list = [body_quats[0]]\n",
    "\n",
    "interp = l+1\n",
    "for i in range(1,body_quats.shape[0]):\n",
    "    q0 = body_quats[i-1]\n",
    "    q1 = body_quats[i]\n",
    "    for j in range(1,interp-1):\n",
    "        a = j/interp\n",
    "        q = qslerp(q0,q1,a)\n",
    "        new_quats_list.append(q)\n",
    "    new_quats_list.append(q1)\n",
    "new_quats = torch.stack(new_quats_list)\n",
    "print('2--->', new_quats.shape)\n",
    "\n",
    "##step3.combine rot to A\n",
    "R = quat2rodrigues(new_quats.reshape(-1,4)).reshape(-1,24,3,3)\n",
    "R = R.cuda()\n",
    "R[:,[12,15,22,23]] = torch.eye(3).reshape(1,1,3,3).cuda()\n",
    "interped_A = hmr_fusioner.smpl(root_rot=R[:,0],pose_rot=R[:,1:])\n",
    "interped_A = interped_A.cpu().numpy()\n",
    "\n",
    "# trajs = np.load(f'{os.path.dirname(video0_fname)}/trajs.npy').reshape((-1,1,3))\n",
    "# trajs[:,:,1] += -1.1\n",
    "# N = min(interped_A.shape[0],trajs.shape[0])\n",
    "# interped_A[:N,:,0:3,3]+=trajs[:N]\n",
    "\n",
    "interped_A = np.matmul(compute_traj.camera_to_world_R,interped_A)\n",
    "\n",
    "interped_A = interped_A.squeeze().reshape((-1,384)).astype(np.float32)\n",
    "interped_A = np.nan_to_num(interped_A)\n",
    "\n",
    "export_Amatrix(f'{video0_fname[:-4]}_new_slerp_fusion2.txt',interped_A, fps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_name = \"reID window\"\n",
    "cv2.namedWindow(window_name)\n",
    "## video1\n",
    "cap0 = cv2.VideoCapture(video0_fname)\n",
    "h0 = int(cap0.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "w0 = int(cap0.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "## video2\n",
    "cap1 = cv2.VideoCapture(video1_fname)\n",
    "h1 = int(cap1.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "w1 = int(cap1.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "\n",
    "height = h0+h1\n",
    "width = max(w0 , w1)\n",
    "canvas = np.zeros((height, width, 3),dtype=np.uint8)\n",
    "mqtt_player = Unity3DMqttPlayer(MQTTPLAYER_CFG)\n",
    "\n",
    "for i in range(1000):\n",
    "    is_valid0,frame0 = cap0.read()\n",
    "    is_valid1,frame1 = cap1.read()\n",
    "    if not is_valid0 or not is_valid1:\n",
    "        break\n",
    "    if i in mview_x2ds_dict:\n",
    "        mqtt_player([0],A[i].reshape(-1,384))\n",
    "        draw_kp(frame0,mview_x2ds_dict[i][0],fmt=\"smpl24\",color=(255,255,255))\n",
    "        draw_kp(frame1,mview_x2ds_dict[i][1],fmt=\"smpl24\",color=(255,255,255))        \n",
    "\n",
    "    canvas[:h0] = frame0\n",
    "    canvas[h0:] = frame1\n",
    "    new_canvas = cv2.resize(canvas,(800,900))\n",
    "    cv2.imshow(window_name,new_canvas)\n",
    "    if cv2.waitKey(5) & 0xFF==ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##step1.interpolate traj\n",
    "interp = 12\n",
    "new_traj = [smoothed_traj[:1]]\n",
    "for i in range(1,smoothed_traj.shape[0]):\n",
    "    p0 = smoothed_traj[i-1]\n",
    "    p1 = smoothed_traj[i]\n",
    "    t = np.linspace(p0,p1,interp)\n",
    "    new_traj.append(t[1:])\n",
    "new_traj = np.concatenate(new_traj,axis=0)\n",
    "print(new_traj.shape)\n",
    "\n",
    "##step2.interpolate quats\n",
    "body_quats = body_quats.cpu()\n",
    "new_quats_list = [body_quats[0]]\n",
    "for i in range(1,body_quats.shape[0]):\n",
    "    q0,q1 = body_quats[i-1],body_quats[i]\n",
    "    for j in range(1,interp-1):\n",
    "        q = qslerp(q0,q1,j/interp)\n",
    "        new_quats_list.append(q)\n",
    "    new_quats_list.append(q1)\n",
    "new_quats = torch.stack(new_quats_list)\n",
    "\n",
    "##step3.combine rot to A\n",
    "R = quat2rodrigues(new_quats.reshape(-1,4)).reshape(-1,24,3,3)\n",
    "R = R.cuda()\n",
    "R[:,[12,15]] = torch.eye(3).reshape(1,1,3,3).cuda()\n",
    "interped_A = hmr_fusioner.smpl(root_rot=R[:,0],pose_rot=R[:,1:])\n",
    "interped_A = interped_A.cpu().numpy()\n",
    "\n",
    "interped_A[...,:3,-1] += new_traj.reshape(-1,1,3)  #update traj in A\n",
    "interped_A = np.matmul(compute_traj.camera_to_world_R,interped_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mqtt_player = Unity3DMqttPlayer(MQTTPLAYER_CFG)\n",
    "for i in range(interped_A.shape[0]):\n",
    "    mqtt_player([0],interped_A[i].reshape(-1,384))\n",
    "    time.sleep(1/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_Amatrix(\"E:/20190727-area51/tripleSalchow_c0_20200115_002.txt\",interped_A,fps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interped_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interped_A.reshape(-1,384).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
