{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "# from ortools.sat.python import cp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../0.mc_utils/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpose.op_formats import NPMapOP25bToSMPL24\n",
    "from openpose.op_utils import draw_kp2d_to_image,draw_reided_bboxes\n",
    "from common.mincostflow import MinCostFlowReID\n",
    "from common.trajectory_solver import MC3DTrajSVDBased\n",
    "\n",
    "from pipeline.mview_x2ds_to_A import SingleX2dsReID,HMRWrapper\n",
    "from pipeline.global_cfg import CFG_SINGLE\n",
    "from mchmr2.hmr_cfg import HMR_ENCODER\n",
    "from mchmr2.hmr_encoder import HMREncoder\n",
    "\n",
    "from mqtt_player.unity3d_mqtt_player import Unity3DMqttPlayer,MQTTPLAYER_CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "##main view\n",
    "op25b_x2ds0 = np.load(\"E:/4.test_videos/yunpeng_mview/01/video_0.npz\",allow_pickle=True)[\"op25b\"].item()\n",
    "video0_fname = \"E:/4.test_videos/yunpeng_mview/01/video_0.mp4\"\n",
    "\n",
    "##sub view\n",
    "op25b_x2ds1 = np.load(\"E:/4.test_videos/yunpeng_mview/01/video_1.npz\",allow_pickle=True)[\"op25b\"].item()\n",
    "video1_fname = \"E:/4.test_videos/yunpeng_mview/01/video_1.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMRCrossviewPairing:\n",
    "    def __init__(self):\n",
    "        self.km = MinCostFlowReID()\n",
    "        \n",
    "    def __call__(self,f0,f1):\n",
    "        \"\"\"\n",
    "        maping f0 to f1\n",
    "        fx is NxD\n",
    "        \"\"\"\n",
    "        M = f0.shape[0]\n",
    "        N = f1.shape[0]\n",
    "        \n",
    "        ##step1. extand features\n",
    "        new_f0 = f0.unsqueeze(1).repeat(1,N,1)#MxNxD\n",
    "        new_f1 = f1.unsqueeze(0).repeat(M,1,1)#MxNxD\n",
    "        \n",
    "        ##step3.KM assign\n",
    "        cost_mat = torch.norm(new_f0-new_f1,dim=-1)\n",
    "        assign = self.km(cost_mat.cpu().numpy().astype(np.int))\n",
    "        return assign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>Loaded HMR from:../12.models/mchmr2/20200516-hmrzero-b4f2048s10-vposer0420.pth\n"
     ]
    }
   ],
   "source": [
    "single_hmr_dict = {}\n",
    "for k in range(2):\n",
    "    single_hmr_dict[k] = SingleX2dsReID(CFG_SINGLE)\n",
    "hmr_simple = HMRWrapper()\n",
    "crossview_matching = HMRCrossviewPairing()\n",
    "map_op25b_to_smpl24 = NPMapOP25bToSMPL24()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "##traj mask related\n",
    "RZ,_ = cv2.Rodrigues(np.array([0,0,np.pi],dtype=np.float32))\n",
    "RY,_ = cv2.Rodrigues(np.array([0,np.pi,0],dtype=np.float32))\n",
    "camera_to_world_R = np.eye(4)\n",
    "camera_to_world_R[:3,:3]= np.matmul(RY,RZ)\n",
    "\n",
    "traj_solver = MC3DTrajSVDBased([2200,2200,960,540])\n",
    "traj_mask = np.array([[-1,1,1]])\n",
    "traj_offset = np.array(CFG_SINGLE.traj_offset).reshape(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block_features: 2048\n",
      "blocks: 5\n",
      "final_features: 512\n",
      "in_features: 96\n",
      "model: ../12.models/mchmr2/20200528-hmrzeofusion-x2b5f2048s5-vposer0420.pth\n",
      "out_features: 43\n",
      ">>>Loaded HMR from:../12.models/mchmr2/20200528-hmrzeofusion-x2b5f2048s5-vposer0420.pth\n",
      ">>>Loaded VPoser from:../12.models/mchmr2/20200420-vposer1024-lt32b3.pth\n"
     ]
    }
   ],
   "source": [
    "mview_cfg = HMR_ENCODER.clone()\n",
    "mview_cfg.hmr.model = \"../12.models/mchmr2/20200528-hmrzeofusion-x2b5f2048s5-vposer0420.pth\"\n",
    "mview_cfg.hmr.in_features=96\n",
    "mview_cfg.hmr.out_features=6+32+5\n",
    "mview_cfg.hmr.blocks=5\n",
    "mview_cfg.freeze()\n",
    "print(mview_cfg.hmr)\n",
    "hmr_mview = HMREncoder(mview_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_trajectory(x2ds,root3ds):\n",
    "    \"\"\"\n",
    "    x2ds shape is Nx24x2,\n",
    "        unit in pixel,\n",
    "        numpy object\n",
    "    root3ds shape is NxJx3, \n",
    "        unit in meter,\n",
    "        numpy object\n",
    "    \"\"\"\n",
    "    assert x2ds.ndim==3 and x2ds.shape[1:]==(24,2)\n",
    "    assert root3ds.ndim==3 and root3ds.shape[1:]==(24,3)\n",
    "\n",
    "    N = x2ds.shape[0]\n",
    "    traj_list = []\n",
    "    mask = (np.abs(x2ds).sum(-1)>0)#Nx24\n",
    "    target_index = {1,2,16,17}\n",
    "    for i in range(N):\n",
    "        select_index = np.nonzero(mask[i])[0]#only available joints are used for traj computing\n",
    "        select_index = list(set.intersection(set(select_index),target_index))\n",
    "        if len(select_index)<2:\n",
    "            traj = np.array([0.,0.,0.])\n",
    "        else:\n",
    "            traj = traj_solver(x2ds[i,select_index],#in pixel unit\n",
    "                               root3ds[i,select_index])#trajs now in mm unit\n",
    "        traj_list.append(traj)\n",
    "    return np.array(traj_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainview_camera = 0\n",
    "subview_camera =1\n",
    "main_x2ds_select = [0,1,2,16,17]\n",
    "def mview_x2ds_to_A(index,x2ds_dict):\n",
    "    \"\"\"\n",
    "    x2ds_dict: key is camera name, value is Mx24x2\n",
    "    \"\"\"\n",
    "    #step1.singleview forward\n",
    "    N = x2ds_dict[mainview_camera].shape[0]\n",
    "    main_hids = None\n",
    "    reid_x2ds_dict = {}\n",
    "    reid_slice_dict = {}\n",
    "    counter = 0\n",
    "    for k in x2ds_dict:\n",
    "        if k not in single_hmr_dict:\n",
    "            print(\">>>Fuck!{} not created?\".format(k))\n",
    "        ret = single_hmr_dict[k].push(index,x2ds_dict[k])##x2ds and hids\n",
    "        if k==mainview_camera:\n",
    "            main_hids = ret[\"hids\"]\n",
    "        reid_x2ds_dict[k]=ret[\"x2ds\"]\n",
    "        reid_slice_dict[k] = slice(counter,counter+ret[\"x2ds\"].shape[0])\n",
    "        counter += ret[\"x2ds\"].shape[0]\n",
    "    ##hmr simple forward\n",
    "    hmr_ret = hmr_simple(torch.cat(list(reid_x2ds_dict.values())))\n",
    "        \n",
    "    #step2.cross matching\n",
    "    f0 = hmr_ret[\"y\"][reid_slice_dict[mainview_camera]]#Nx32\n",
    "    f1 = hmr_ret[\"y\"][reid_slice_dict[subview_camera]]#Nx32\n",
    "    cross_assign = crossview_matching(f0,f1)\n",
    "\n",
    "    #step3.match x2ds\n",
    "    match_x2ds_list = []\n",
    "    unmatch_x2ds_list = []\n",
    "    match_hids_list = []\n",
    "    unmatch_hids_list= []\n",
    "    for i in range(N):\n",
    "        x0 = reid_x2ds_dict[mainview_camera][i]\n",
    "        hid = main_hids[i]\n",
    "        if i in cross_assign:\n",
    "            mid = cross_assign[i][0] # matched index in subview\n",
    "            x1 = reid_x2ds_dict[subview_camera][mid]#24x2\n",
    "            match_x2ds_list.append(torch.stack([x0,x1]))\n",
    "            match_hids_list.append(hid)\n",
    "        else:\n",
    "            unmatch_x2ds_list.append(x0)\n",
    "            unmatch_hids_list.append(hid)\n",
    "    ##matched\n",
    "    match_x2ds = None\n",
    "    match_hids = None\n",
    "    if len(match_x2ds_list)>0:\n",
    "        match_x2ds = torch.stack(match_x2ds_list)\n",
    "        match_hids = np.array(match_hids_list)\n",
    "    ##unmatched\n",
    "    unmatch_x2ds = None\n",
    "    unmatch_hids = None\n",
    "    if len(unmatch_x2ds_list)>0:\n",
    "        unmatch_x2ds = torch.stack(unmatch_x2ds_list)\n",
    "        unmatch_hids = np.array(unmatch_hids_list)\n",
    "    return {\"matched_x2ds\":match_x2ds, ##NxCx24x2\n",
    "            \"matched_hids\":match_hids,\n",
    "            \"unmatched_x2ds\":unmatch_x2ds, ##Nx24x2\n",
    "            \"unmatched_hids\":unmatch_hids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_name = \"reID window\"\n",
    "cv2.namedWindow(window_name)\n",
    "## video1\n",
    "cap0 = cv2.VideoCapture(video0_fname)\n",
    "h0 = int(cap0.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "w0 = int(cap0.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "## video2\n",
    "cap1 = cv2.VideoCapture(video1_fname)\n",
    "h1 = int(cap1.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "w1 = int(cap1.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "\n",
    "height = h0+h1\n",
    "width = max(w0 , w1)\n",
    "canvas = np.zeros((height, width, 3),dtype=np.uint8)\n",
    "mqtt_player = Unity3DMqttPlayer(MQTTPLAYER_CFG)\n",
    "\n",
    "for i in range(1000):\n",
    "    is_valid0,frame0 = cap0.read()\n",
    "    is_valid1,frame1 = cap1.read()\n",
    "    if not is_valid0 or not is_valid1:\n",
    "        break\n",
    "        \n",
    "    #step1.load data from each view\n",
    "    if i in op25b_x2ds0 and i in op25b_x2ds1:\n",
    "        ts = time.time()\n",
    "        ##step1.load x2ds\n",
    "        x2ds0 = map_op25b_to_smpl24(op25b_x2ds0[i])[...,:2] #Nx24x3\n",
    "        x2ds1 = map_op25b_to_smpl24(op25b_x2ds1[i])[...,:2] #Mx24x3\n",
    "        \n",
    "        ##step2.assemble mview dict\n",
    "        assign_ret = mview_x2ds_to_A(i,{0:x2ds0,1:x2ds1})\n",
    "        ts = time.time()-ts\n",
    "#         print(ts)\n",
    "        matched_x2ds = assign_ret[\"matched_x2ds\"]\n",
    "        matched_hids = assign_ret[\"matched_hids\"]\n",
    "#         print(matched_x2ds.shape)\n",
    "        N = matched_x2ds.shape[0]\n",
    "        for i in range(N):\n",
    "            draw_kp2d_to_image(frame0,matched_x2ds[i,0],color=(255,0,0))\n",
    "            draw_reided_bboxes(frame0,matched_x2ds[i,0].numpy(),matched_hids[i])\n",
    "            draw_kp2d_to_image(frame1,matched_x2ds[i,1],color=(255,0,0))\n",
    "            draw_reided_bboxes(frame1,matched_x2ds[i,1].numpy(),matched_hids[i])\n",
    "        \n",
    "        ##step3.fusion\n",
    "#         print(matched_x2ds.shape)\n",
    "        ret = hmr_mview.forward_hmr(matched_x2ds)\n",
    "        A = hmr_mview.forward_smpl(ret[\"root_r6d\"],ret[\"pose_r6d\"])\n",
    "        A = A.cpu().numpy()\n",
    "        \n",
    "        ##step4.from camera space A to world space in Unity3D\n",
    "        np_in_x2ds = matched_x2ds[:,mainview_camera].numpy()\n",
    "        trajs = compute_trajectory(np_in_x2ds,A[...,:3,-1])*traj_mask + traj_offset\n",
    "#         for i in range(N):\n",
    "#             trajs[i,[0,2]] = ret_reid[\"humans\"][i].traj_filter(index,trajs[i,[0,2]])\n",
    "#             A[i,:,:3,-1] += trajs[i].reshape(1,3)  #update traj in A\n",
    "        A[...,:3,-1] += trajs.reshape(-1,1,3)\n",
    "        A = np.matmul(camera_to_world_R,A)\n",
    "        \n",
    "        mqtt_player(matched_hids,A.reshape(-1,384))\n",
    "    \n",
    "    canvas[:h0] = frame0\n",
    "    canvas[h0:] = frame1\n",
    "    new_canvas = cv2.resize(canvas,(800,900))\n",
    "    cv2.imshow(window_name,new_canvas)\n",
    "    if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
